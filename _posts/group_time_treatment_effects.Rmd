---
title: "Thinking about Group-Time Average Treatment Effects"
output:
  md_document:
    variant: "markdown"
    preserve_yaml: TRUE
author: "brant"
date: '2021-04-20'
layout: posts
permalink: /posts/group-time-average-treatment-effects
categories:
  - Econometrics
  - Policy Evaluation
  - Panel Data
---


# Introduction

One of my recent projects, [Difference-in-Differences with Multiple Time Periods](https://doi.org/10.1016/j.jeconom.2020.12.001) (with Pedro H.C. Sant'Anna, Forthcoming at *Journal of Econometrics*) [[Arxiv](https://arxiv.org/abs/1803.09015)], has gotten at lot of attention lately (well, at least a lot of attention relative to my other papers...)

In that paper, we propose a way to implement a DID identification strategy that gets around some problems with two-way fixed effects regressions (particularly in the case with treatment effect heterogeneity and variation in treatment timing).  [There are lots of recent discussions of these issues, so I'll just point you to the [discussion in our `did` package](https://bcallaway11.github.io/did/articles/multi-period-did.html)]

Our solution in that paper is really pretty simple --- first, we divide the data into "groups" based on the time period when units become treated; second, compute group-time average treatment effects (which amounts to two-by-two sort of difference in differences argument); and third, we aggregate those group-time average treatment effects into either an overall treatment effect parameter or into event-study type of plot (there are other possibilities too).

My impression is that most people consider the main contribution of that paper to be an approach to doing difference in differences with multiple time periods and variation in treatment timing that is robust to treatment effect heterogeneity.  To be fair, that is probably right, but, at least in my mind, these are two separate contributions: (i) introducing group-time average treatment effects as a target parameter when a researcher has access to repeated observations over time, and (ii) using difference in differences (and its variations: conditional parallel trends assumptions, treatment effect anticipation, a variety of possible comparison groups) to identify group-time average treatment effects.

I have a couple of recent projects where there continues to be variation in treatment timing so that it is natural to want to identify group-time average treatment effects and want to aggregate them into overall treatment effect parameters or into event-studies, but where difference in differences is not an appropriate identification strategy.  In this post, I want to write briefly about thost two projects as well as show some code that I think could be helpful for researchers that are dealing with staggered treatment adoption but want to implement an alternative estimator.  In general, my sense is that, if a researcher can handle estimating a treatment effect parameter in the case with one group (so not dealing with variation in treatment timing) then it should be relatively straightforward to extend those arguments to the case with multiple groups.  

One of my on-going goals is to `modularize` our code from the `did` package with the aim of researchers being able to "break-off" parts (e.g., organizing groups/time periods or the aggregation step) while replacing some parts (e.g., the difference in differences step) with their own code.

# Two (Seemingly Unrelated?) Projects

## Treatment Effects in Interactive Fixed Effects Models

The first project I want to mention is [Treatment Effects in Interactive Fixed Effects Models](https://arxiv.org/abs/2006.15780) (with Sonia Karami).  In this paper, we are interested in treatment effects in the case where untreated potential outcomes are generated by an interactive fixed effects model such as

\$$
  Y_{it}(0) = \theta_t + \eta_i + \lambda_i F_t + X_i'\beta_t + u_{it}
\$$
where $\theta_t$ is a time fixed effect, $\eta_i$ and $\lambda_i$ are individual fixed effects, $F_t$ is the "effect" of $\lambda_i$  which could vary over time (this is the interactive fixed effects which implies that DID won't work, generally, in this case and is the source of all the challenges in the paper), $X_i$ are observed covariates, and $u_{it}$ is an idiosyncratic error term.

As a couple of side-comments:

* For applied researchers, I think there is a lot to like about interactive fixed effects models.  For one thing, they generalize both DID and linear trends models that are common in applied work.  One of the other things that I like about this model is that, if we observed $\lambda_i$, this sort of model is likely how an applied researcher would include it in the model --- which is not the case for the linear trends model.

In this paper, we are interested in 

\$$
  ATT_t = E[Y_t(1) - Y_t(0) | D=1]
\$$

which is the average treatment effect on the treated in time period $t$ among units in the treated group.  I'll spare you some of the details here, but essentially our identification argument amounts to trying to find a covariate whose effect does not vary over time (so that at least one element in \$$ \beta_t \$$ is actually constant over time) and use that covariate to generate an extra moment condition in order to identify the parameters in the model for untreated potential outcomes, which, in turn, is enough to identify $ATT_t$.

The application in that paper is about trying to estimate the effect of job displacement.  In that case, one might think that, in the absence of job displacement, earnings could depend on unobserved "skill", that the distribution of skill differs among displaced and non-displaced workers, and that the return to skill could change over time.  In this case, this sort of interactive fixed effects model seems appealing.  We use data from NLSY79, but one practical difficulty is that, in any given year, the number of displaced workers is not that large (typically 50-100 out of several thousand total observations).  In addition, workers become displaced at different points in time.  Together, these suggest somehow pooling groups and time periods together to estimate effects of job displacement.

Group-time average treatment effects give us a relatively straightforward path here.  Essentially, we implement our identification strategy separately for each group so that we identify/estimate:

\$$
  ATT(g,t) = E[Y_t(g) - Y_t(0) | G=g]
\$$

which is the average effect of participating in the treatment for group g in time period t.

## Policy Evaluation during a Pandemic

I have also been working with Tong Li on two projects related to the Covid-19 pandemic.  The first project is about partially identifying treatment effect parameters early in the pandemic.  There we used an ``unconfoundedness'' strategy, but the partial identification resulted from testing not being widely available and nonrandomly administered.  One comment that we used to get on that paper was: Why use unconfoundedness rather than difference in differences?  To tell the truth, we weren't totally sure --- we just had the sense that the pandemic was "highly nonlinear" and that it therefore made more sense to use an unconfoundedness type of strategy relative to difference in differences.

We were interested enough in this topic though that we decided to work all this out.  

In that paper, we try to estimate the effects of stay-at-home orders on Covid-19 cases and on the amount of travel with the idea of comparing states that implemented the policy to states that didn't implement the policy (or implemented it later) conditional on having the same values of pandemic related variables (e.g., Covid-19 cases, number of tests, and population size, among others) before the polilcy was implemented.  Once again, though, estimating the effect of these policies is made more complicated because the timing of policies varied across states.  


# Code

You can think about group-time average treatment effect code involving four steps:

1. Organize data into groups, decide which time periods to compute ATT(g,t) for.

    * For `did`, this step involves dropping units that are treated in the first time period and aiming to compute ATT(g,t) in all other periods besides the first (when g is less than t, this amounts to a pseudo group-time average treatment effect that can be used for pre-testing)
	* For `covid`, same as `did`
	* For `ife`, we need to drop the first two periods (more if \$$ \lambda \$$ is a vector) and compute ATT(g,t) in all other periods
	
2. For each group and time period from Step 1, compute an ATT(g,t).  This step is the one that is distinct for any new approach.

    * For `did`, this amounts to implementing a 2x2 DID estimator (possibly including conditioning on covariates, allowing for anticipation, or various comparison groups)
	* For `covid`, we our estimator was a doubly robust version of unconfoundedness, but there are other possibilities like matching
	* For `ife`, we implemented our interactive fixed effects estimator for \$$ ATT_t \$$ but separately by group.
	
3. Report \$$ ATT(g,t) \$$, standard errors, etc.

    * This is often a good step to rely on existing code

4. Aggregate \$$ ATT(g,t) \$$ into parameter of interest such as an overall ATT or an event study

    * This is another step where existing code can be re-used.



# r code
```{r}
1+1
```

# hidden r code
```{r, echo=FALSE}
2+2
```

<!-- 
# some math

\$$
1+1 = 2
\$$
