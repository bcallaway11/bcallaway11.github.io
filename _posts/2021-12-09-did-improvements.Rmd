---
title: "Faster did Code"
output:
  html_document:
    variant: "markdown_github"
    preserve_yaml: TRUE
author: "brant"
date: '2021-11-09'
layout: single
permalink: /posts/did-improvements
categories:
  - Econometrics
  - Panel Data
  - did package
comments: true
---


```{r echo=FALSE}
base.dir <- "~/Dropbox/website/"
base.url <- "/"
fig.path <- "files/figures/"
# set knitr parameters
knitr::opts_knit$set(base.dir = base.dir, base.url = base.url)
knitr::opts_chunk$set(fig.path = fig.path) 
```

# Introduction

We just put out a big update to the `did` package (version 2.1).  It is on GitHub and should be on CRAN in a day or two.  This version contains a lot of behind-the-scenes improvement such as better error handling and substantially more thorough testing.  It also allows users to [use a universal base period in event studies](posts/event-study-universal-v-varying-base-period).

This post though is about speed improvements in the new version of the `did` package.  Here is some code


## Example 1: Balanced Panel Data

```{r}
library(did)
packageVersion("did") # version 2.1.0

n <- 5000
time.periods <- 8
sp <- reset.sim(n=n, time.periods=time.periods)

data <- build_sim_dataset(sp)
N <- nrow(data)
# add some more spurious columns to data:
data$X1 <- sample(1:25, size=N, replace=TRUE)
data$X1 <- as.factor(data$X1)
data$X2 <- rnorm(N)
data$X3 <- rnorm(N)
data$X4 <- rnorm(N)
data$X5 <- rnorm(N)

pt <- proc.time()
new_dr <- att_gt(yname="Y", xformla=~X, data=data, tname="period", idname="id",
                  gname="G", est_method="dr")
new_time <- proc.time() - pt

# currently on CRAN
detach("package:did")
library(did, lib.loc="~/R/old_packages") 
packageVersion("did") # should be 2.0.0

pt <- proc.time()
old_dr <- att_gt(yname="Y", xformla=~X, data=data, tname="period", idname="id",
                  gname="G", est_method="dr")
old_time <- proc.time() - pt

# check that estimates are the same
all(new_dr$att == old_dr$att)

# compare actual times
new_time
old_time
```

There is may be a little bit of variation due to compiling the source file for this post, but I get about a 70% reduction in computational time with the new code (from 4.6 to 1.3 seconds).

## Example 2: Unbalanced Panel Data

```{r}
detach("package:did")
library(did)
packageVersion("did") # version 2.1.0

n <- 5000
time.periods <- 8
sp <- reset.sim(n=n, time.periods=time.periods)

data <- build_sim_dataset(sp)
N <- nrow(data)
# add some more spurious columns to data:
data$X1 <- sample(1:25, size=N, replace=TRUE)
data$X1 <- as.factor(data$X1)
data$X2 <- rnorm(N)
data$X3 <- rnorm(N)
data$X4 <- rnorm(N)
data$X5 <- rnorm(N)
data <- data[-1, ] # drop first row

pt <- proc.time()
new_dr <- att_gt(yname="Y", xformla=~X, data=data, tname="period", idname="id",
                  gname="G", est_method="dr", allow_unbalanced_panel = TRUE)
new_time <- proc.time() - pt

# currently on CRAN
detach("package:did")
library(did, lib.loc="~/R/old_packages") 
packageVersion("did") # should be 2.0.0

pt <- proc.time()
old_dr <- att_gt(yname="Y", xformla=~X, data=data, tname="period", idname="id",
                  gname="G", est_method="dr", allow_unbalanced_panel = TRUE)
old_time <- proc.time() - pt

# check that estimates are the same
all(new_dr$att == old_dr$att)

# compare actual times
new_time
old_time
```

Again, there may be variation due to compiling the document, but here I get about a 97% reduction in computation time (from 52 seconds to about 1.5 seconds).

## Example 3: Repeated cross sections data

```{r}
detach("package:did")
library(did)
packageVersion("did") # version 2.1.0

n <- 5000
time.periods <- 8
sp <- reset.sim(n=n, time.periods=time.periods)

data <- build_sim_dataset(sp, panel=FALSE)
N <- nrow(data)
# add some more spurious columns to data:
data$X1 <- sample(1:25, size=N, replace=TRUE)
data$X1 <- as.factor(data$X1)
data$X2 <- rnorm(N)
data$X3 <- rnorm(N)
data$X4 <- rnorm(N)
data$X5 <- rnorm(N)
data <- data[-1, ] # drop first row

pt <- proc.time()
new_dr <- att_gt(yname="Y", xformla=~X, data=data, tname="period", idname="id",
                  gname="G", est_method="dr", panel=FALSE)
new_time <- proc.time() - pt

# currently on CRAN
detach("package:did")
library(did, lib.loc="~/R/old_packages") 
packageVersion("did") # should be 2.0.0

pt <- proc.time()
old_dr <- att_gt(yname="Y", xformla=~X, data=data, tname="period", idname="id",
                  gname="G", est_method="dr", panel=FALSE)
old_time <- proc.time() - pt

# check that estimates are the same
all(new_dr$att == old_dr$att)

# compare actual times
new_time
old_time
```

In this case, I get about a 75% reduction in computation time (from 2.8 to 0.6 seconds).

## Example 4: Bigger data

```{r}
detach("package:did")
library(did)
packageVersion("did") # version 2.1.0

n <- 25000
time.periods <- 20
sp <- reset.sim(n=n, time.periods=time.periods)

data <- build_sim_dataset(sp)
N <- nrow(data)
# add some more spurious columns to data:
data$X1 <- sample(1:25, size=N, replace=TRUE)
data$X1 <- as.factor(data$X1)
data$X2 <- rnorm(N)
data$X3 <- rnorm(N)
data$X4 <- rnorm(N)
data$X5 <- rnorm(N)
data <- data[-1, ] # drop first row

pt <- proc.time()
new_dr <- att_gt(yname="Y", xformla=~X, data=data, tname="period", idname="id",
                  gname="G", est_method="dr")
new_time <- proc.time() - pt

# currently on CRAN
detach("package:did")
library(did, lib.loc="~/R/old_packages") 
packageVersion("did") # should be 2.0.0

pt <- proc.time()
old_dr <- att_gt(yname="Y", xformla=~X, data=data, tname="period", idname="id",
                  gname="G", est_method="dr")
old_time <- proc.time() - pt

# check that estimates are the same
all(new_dr$att == old_dr$att)

# compare actual times
new_time
old_time
```

This is about a 73% reduction in computation time (from 155 to 42 seconds for me).

## Conclusion

I hope you'll find the code useful.  As always, feel free to contact me if you run into issues.
